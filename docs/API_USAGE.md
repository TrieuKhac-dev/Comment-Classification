# API Usage Guide - H∆∞·ªõng d·∫´n S·ª≠ d·ª•ng API

## üöÄ Kh·ªüi ƒë·ªông Server

### C√†i ƒë·∫∑t Dependencies

```bash
pip install fastapi uvicorn pydantic
```

Ho·∫∑c c√†i ƒë·∫∑t t·∫•t c·∫£ t·ª´ requirements.txt:

```bash
pip install -r requirements.txt
```

### Ch·∫°y Server

```bash
# C√°ch 1: Ch·∫°y tr·ª±c ti·∫øp
python src/api_server.py

# C√°ch 2: S·ª≠ d·ª•ng uvicorn
uvicorn src.api_server:app --host 0.0.0.0 --port 8000 --reload
```

Server s·∫Ω ch·∫°y t·∫°i: **http://localhost:8000**

---

## üìñ API Documentation

Khi server ƒëang ch·∫°y, truy c·∫≠p:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## üîå API Endpoints

### 1. Health Check

```bash
GET /
GET /health
```

**Response:**

```json
{
  "status": "healthy",
  "model_loaded": true,
  "services_ready": true
}
```

---

### 2. Predict Comments (Main Endpoint)

```bash
POST /predict
Content-Type: application/json
```

**Request Body:**

```json
{
  "comments": {
    "1": "S·∫£n ph·∫©m r·∫•t t·ªët, t√¥i r·∫•t h√†i l√≤ng!",
    "2": "ƒê·ªì r√°c, l·ª´a ƒë·∫£o, ƒë·ª´ng mua!",
    "3": "Giao h√†ng nhanh, ƒë√≥ng g√≥i c·∫©n th·∫≠n"
  }
}
```

**Response:**

```json
{
  "results": {
    "1": {
      "is_violation": false,
      "violation_probability": 0.15,
      "comment": "S·∫£n ph·∫©m r·∫•t t·ªët, t√¥i r·∫•t h√†i l√≤ng!"
    },
    "2": {
      "is_violation": true,
      "violation_probability": 0.92,
      "comment": "ƒê·ªì r√°c, l·ª´a ƒë·∫£o, ƒë·ª´ng mua!"
    },
    "3": {
      "is_violation": false,
      "violation_probability": 0.08,
      "comment": "Giao h√†ng nhanh, ƒë√≥ng g√≥i c·∫©n th·∫≠n"
    }
  },
  "total_comments": 3,
  "violation_count": 1
}
```

---

### 3. Simple Predict (Alternative Endpoint)

```bash
POST /predict/simple
Content-Type: application/json
```

**Request Body:**

```json
["S·∫£n ph·∫©m t·ªët", "ƒê·ªì r√°c", "Giao h√†ng nhanh"]
```

**Response:**

```json
{
  "predictions": [
    {
      "comment": "S·∫£n ph·∫©m t·ªët",
      "is_violation": false,
      "violation_probability": 0.12
    },
    {
      "comment": "ƒê·ªì r√°c",
      "is_violation": true,
      "violation_probability": 0.85
    },
    {
      "comment": "Giao h√†ng nhanh",
      "is_violation": false,
      "violation_probability": 0.05
    }
  ]
}
```

---

## üíª Code Examples

### Python (requests)

```python
import requests

# API endpoint
url = "http://localhost:8000/predict"

# Request data
data = {
    "comments": {
        "1": "S·∫£n ph·∫©m r·∫•t t·ªët!",
        "2": "ƒê·ªì r√°c, l·ª´a ƒë·∫£o!",
        "3": "Giao h√†ng nhanh"
    }
}

# G·ª≠i request
response = requests.post(url, json=data)

# X·ª≠ l√Ω response
if response.status_code == 200:
    result = response.json()

    print(f"T·ªïng s·ªë b√¨nh lu·∫≠n: {result['total_comments']}")
    print(f"S·ªë b√¨nh lu·∫≠n vi ph·∫°m: {result['violation_count']}")
    print()

    for comment_id, prediction in result['results'].items():
        status = "‚ùå VI PH·∫†M" if prediction['is_violation'] else "‚úÖ H·ª¢P L·ªÜ"
        prob = prediction['violation_probability']
        comment = prediction['comment']

        print(f"ID {comment_id}: {status}")
        print(f"  B√¨nh lu·∫≠n: {comment}")
        print(f"  X√°c su·∫•t vi ph·∫°m: {prob:.2%}")
        print()
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

### Python (httpx - async)

```python
import httpx
import asyncio

async def predict_comments(comments_dict):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/predict",
            json={"comments": comments_dict},
            timeout=30.0
        )
        return response.json()

# S·ª≠ d·ª•ng
comments = {
    "1": "S·∫£n ph·∫©m t·ªët",
    "2": "ƒê·ªì r√°c"
}

result = asyncio.run(predict_comments(comments))
print(result)
```

### cURL

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "comments": {
      "1": "S·∫£n ph·∫©m r·∫•t t·ªët!",
      "2": "ƒê·ªì r√°c, l·ª´a ƒë·∫£o!"
    }
  }'
```

### JavaScript (fetch)

```javascript
const url = "http://localhost:8000/predict";

const data = {
  comments: {
    1: "S·∫£n ph·∫©m r·∫•t t·ªët!",
    2: "ƒê·ªì r√°c, l·ª´a ƒë·∫£o!",
  },
};

fetch(url, {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
  },
  body: JSON.stringify(data),
})
  .then((response) => response.json())
  .then((result) => {
    console.log("Total comments:", result.total_comments);
    console.log("Violations:", result.violation_count);

    for (const [id, prediction] of Object.entries(result.results)) {
      console.log(`\nID ${id}:`);
      console.log(`  Comment: ${prediction.comment}`);
      console.log(`  Is violation: ${prediction.is_violation}`);
      console.log(
        `  Probability: ${(prediction.violation_probability * 100).toFixed(2)}%`
      );
    }
  })
  .catch((error) => console.error("Error:", error));
```

### Node.js (axios)

```javascript
const axios = require("axios");

const data = {
  comments: {
    1: "S·∫£n ph·∫©m r·∫•t t·ªët!",
    2: "ƒê·ªì r√°c, l·ª´a ƒë·∫£o!",
  },
};

axios
  .post("http://localhost:8000/predict", data)
  .then((response) => {
    const result = response.data;
    console.log("Results:", result);
  })
  .catch((error) => {
    console.error("Error:", error.response?.data || error.message);
  });
```

---

## üîß Production Deployment

### Docker

T·∫°o `Dockerfile`:

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "src.api_server:app", "--host", "0.0.0.0", "--port", "8000"]
```

Build v√† ch·∫°y:

```bash
docker build -t comment-classification-api .
docker run -p 8000:8000 comment-classification-api
```

### Systemd Service (Linux)

T·∫°o file `/etc/systemd/system/comment-api.service`:

```ini
[Unit]
Description=Comment Classification API
After=network.target

[Service]
Type=simple
User=www-data
WorkingDirectory=/path/to/CommentClassification
Environment="PATH=/path/to/venv/bin"
ExecStart=/path/to/venv/bin/uvicorn src.api_server:app --host 0.0.0.0 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
```

Kh·ªüi ƒë·ªông:

```bash
sudo systemctl enable comment-api
sudo systemctl start comment-api
sudo systemctl status comment-api
```

### Nginx Reverse Proxy

```nginx
server {
    listen 80;
    server_name api.example.com;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

---

## ‚ö° Performance Tips

### 1. Workers (Production)

```bash
uvicorn src.api_server:app --host 0.0.0.0 --port 8000 --workers 4
```

### 2. GPU Acceleration

Ch·ªânh s·ª≠a `config/model/embedding.py`:

```python
sbert_config = SBERTEmbeddingConfig(
    device='cuda'  # S·ª≠ d·ª•ng GPU
)
```

### 3. Batch Processing

API t·ª± ƒë·ªông x·ª≠ l√Ω batch. G·ª≠i nhi·ªÅu comments c√πng l√∫c ƒë·ªÉ t·ªëi ∆∞u:

```python
# ‚úÖ GOOD: Batch request
comments = {str(i): text for i, text in enumerate(large_list)}
response = requests.post(url, json={"comments": comments})

# ‚ùå BAD: Multiple single requests
for text in large_list:
    requests.post(url, json={"comments": {"1": text}})
```

---

## üêõ Troubleshooting

### L·ªói: "Model not found"

```bash
# Train model tr∆∞·ªõc khi start server
python src/train_main.py
```

### L·ªói: "Address already in use"

```bash
# ƒê·ªïi port
uvicorn src.api_server:app --port 8001
```

### L·ªói: CUDA out of memory

```python
# Chuy·ªÉn v·ªÅ CPU trong config/model/embedding.py
sbert_config = SBERTEmbeddingConfig(device='cpu')
```

---

## üìä Monitoring

### Health Check

```bash
# Ki·ªÉm tra server
curl http://localhost:8000/health
```

### Logs

Server logs ƒë∆∞·ª£c l∆∞u trong `logs/` folder.

```bash
# Xem logs realtime
tail -f logs/training_*.log
```

---

## üîí Security (Production)

### 1. API Key Authentication

Th√™m v√†o `api_server.py`:

```python
from fastapi import Header, HTTPException

async def verify_api_key(x_api_key: str = Header(...)):
    if x_api_key != "your-secret-key":
        raise HTTPException(status_code=401, detail="Invalid API key")

@app.post("/predict", dependencies=[Depends(verify_api_key)])
async def predict_comments_endpoint(request: CommentRequest):
    # ...
```

### 2. Rate Limiting

```bash
pip install slowapi
```

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/predict")
@limiter.limit("100/minute")
async def predict_comments_endpoint(request: Request, ...):
    # ...
```

---

## üìà Metrics & Analytics

### Prometheus Integration

```python
from prometheus_fastapi_instrumentator import Instrumentator

Instrumentator().instrument(app).expose(app)
```

Metrics available at: `http://localhost:8000/metrics`

---

## ‚ùì FAQ

**Q: API c√≥ h·ªó tr·ª£ HTTPS kh√¥ng?**  
A: S·ª≠ d·ª•ng nginx ho·∫∑c reverse proxy v·ªõi SSL certificate.

**Q: C√≥ th·ªÉ x·ª≠ l√Ω bao nhi√™u requests/gi√¢y?**  
A: Ph·ª• thu·ªôc v√†o hardware. CPU: ~10 req/s, GPU: ~50 req/s.

**Q: API c√≥ cache predictions kh√¥ng?**  
A: Model t·ª± ƒë·ªông cache features, nh∆∞ng predictions kh√¥ng cache (real-time).

**Q: C√≥ th·ªÉ ch·∫°y multiple workers kh√¥ng?**  
A: C√≥, d√πng `--workers N` v·ªõi uvicorn.

---

**Happy API Usage! üöÄ**
